{"cells":[{"cell_type":"code","source":["import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom pyspark.sql.types import FloatType, IntegerType\n# data from MovieLens|GroupLens(http://files.grouplens.org/datasets/movielens/ml-latest-small.zip)\n# File location and type\nfile_location = \"/FileStore/tables/movies.csv\"\nfile_type = \"csv\"\ndisplay(df)\nmovie_data = df.toPandas()\nmovie_data.head()\n\n\n# CSV options\ninfer_schema = \"false\"\nfirst_row_is_header = \"true\"\ndelimiter = \",\"\n\n# The applied options are for CSV files. For other file types, these will be ignored.\ndf = spark.read.format(file_type) \\\n  .option(\"inferSchema\", infer_schema) \\\n  .option(\"header\", first_row_is_header) \\\n  .option(\"sep\", delimiter) \\\n  .load(file_location)\n\n# converting string column types to Float and Integer\nfor col in df.columns:\n  if col in ['movieId']:\n    df = df.withColumn(col, df[col].cast(IntegerType()))\n\ndisplay(df)\nmovie_data = df.toPandas()\n#movie_data.head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-524007686795444&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      8</span> file_location <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#34;/FileStore/tables/movies.csv&#34;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      9</span> file_type <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#34;csv&#34;</span>\n<span class=\"ansi-green-fg\">---&gt; 10</span><span class=\"ansi-red-fg\"> </span>display<span class=\"ansi-blue-fg\">(</span>df<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     11</span> movie_data <span class=\"ansi-blue-fg\">=</span> df<span class=\"ansi-blue-fg\">.</span>toPandas<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     12</span> movie_data<span class=\"ansi-blue-fg\">.</span>head<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;df&#39; is not defined</div>"]}}],"execution_count":1},{"cell_type":"code","source":["_df = df.groupBy('genres').count()\ndisplay(_df.sort('count', ascending =False).limit(100))"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["# File location and type\nfile_location = \"/FileStore/tables/ratings.csv\"\nfile_type = \"csv\"\n\n# CSV options\ninfer_schema = \"false\"\nfirst_row_is_header = \"true\"\ndelimiter = \",\"\n\n# The applied options are for CSV files. For other file types, these will be ignored.\ndf = spark.read.format(file_type) \\\n  .option(\"inferSchema\", infer_schema) \\\n  .option(\"header\", first_row_is_header) \\\n  .option(\"sep\", delimiter) \\\n  .load(file_location)\n\ndisplay(df)\n\n# converting string column types to Float and Integer\nfor col in df.columns:\n  if col in ['rating', 'timestamp']:\n    df = df.withColumn(col, df[col].cast(FloatType()))\n  if col in ['userId', 'movieId']:\n    df = df.withColumn(col, df[col].cast(IntegerType()))\n\nmovie_ratings=df.toPandas()\n#movie_ratings.head()"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["R_df = df.groupBy('rating').count()\ndisplay(R_df.sort('count', ascending =False))"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["movie_ratings\nmovie_data\n\njoined = movie_data.join(movie_ratings, on='movieId', how='left', lsuffix='_', sort=True)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["joined.drop(['movieId_', 'genres', 'userId', 'movieId', 'timestamp'], inplace=True, axis=1)\n"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["joined.head()"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["display(joined.sort_values('rating', ascending=False))"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["FloatType()"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["def movieTitle(movieId):\n    title = movie_data.at[movieId, 'title']\n    return title\nmovieTitle(1)\n"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["def movieGenre(movieId):  \n    genre = movie_data.at[movieId, 'genres']\n    return  genre\nmovieGenre(1)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["# Data Preprocessing for huge dataset (However here Not Required)\n# to select only those movies whose id is present in movie_data\n# movie_ratings = movie_ratings[movie_ratings['movieId'].isin(movie_data.index)]\n\ndef favMovie(userId, N):\n    userRatings = movie_ratings[movie_ratings.userId==userId]\n    sortedRatings = pd.DataFrame.sort_values(userRatings,['rating'] ,ascending=[0])[:N]\n    sortedRatings['Title'] = sortedRatings['movieId'].apply(movieTitle)\n    sortedRatings['Genre'] = sortedRatings['movieId'].apply(movieGenre)\n    return sortedRatings\nfavMovie(1, 12)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["movie_ratings.shape, movie_data.shape"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["userPerMovieID = movie_ratings.movieId.value_counts()\nuserPerMovieID.head()"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["userPerMovieID.shape"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["## Data Preprocessing to obtain less sparse matrix for huge dataset(However here Not Required)\n ## Take only those movies which are seen by more than 10 users\n#movie_ratings = movie_ratings[movie_ratings.index.isin(userPerMovieID[userPerMovieID > 10].index)]\n#movie_ratings.shape\nuserMovieRatingMatrix = pd.pivot_table(movie_ratings, index=['userId'],columns=['movieId'] ,values='rating')\nuserMovieRatingMatrix.head(10)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["user1 = 100\nuser2 = 200\n\nuser1_ratings = userMovieRatingMatrix.transpose()[user1]\nuser1_ratings.head()"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["user2_ratings = userMovieRatingMatrix.transpose()[user2]\nuser2_ratings.head()"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["from scipy.spatial.distance import hamming\n# hamming() returns a value which shows the pecentage of disagreement\n\nhamming(user1_ratings, user1_ratings)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["# Wrapping it up in a function\ndef distance(user1, user2):\n    try:\n        user1_ratings = userMovieRatingMatrix.transpose()[user1]\n        user2_ratings = userMovieRatingMatrix.transpose()[user2]\n        distance = hamming(user1_ratings, user2_ratings)\n    except:\n        distance = np.nan\n    return distance\ndistance(100,200)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["user = 1\nallusers = pd.DataFrame(userMovieRatingMatrix.index)\n# Removing the activee user\nallusers = allusers[allusers.userId != user]\nallusers.head()"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["allusers['distance'] = allusers['userId'].apply(lambda x: distance(user, x))\nallusers.head()"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["K = 10\nKNearestUsers = allusers.sort_values(['distance'], ascending=True)['userId'][:K]\nKNearestUsers"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["# Wrapping it up in a function\ndef nearestNeighbours(user, K=10):\n    allusers = pd.DataFrame(userMovieRatingMatrix.index)\n    allusers = allusers[allusers.userId != user]\n    allusers['distance'] = allusers['userId'].apply(lambda x: distance(user, x))\n    KNearestUsers = allusers.sort_values(['distance'], ascending=True)['userId'][:K]\n    return KNearestUsers\n\nKNearestNeighbours = nearestNeighbours(1,5)\nKNearestNeighbours"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["# Nearest Neighbours ratings\n\nNNratings = userMovieRatingMatrix[userMovieRatingMatrix.index.isin(KNearestNeighbours)]\nNNratings\n"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["#Getting the average rating of each movie seen by Nearest Neighbours of active user\navgRating = NNratings.apply(np.nanmean).dropna()\navgRating.head()\n\n# warning where the columns of NNratings are completely empty(nan)"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["moviesAlreadySeen = userMovieRatingMatrix.transpose()[user].dropna().index\nmoviesAlreadySeen"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["# Removing the movies which are already seen by user\navgRating = avgRating[~avgRating.index.isin(moviesAlreadySeen)]"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["N=3\ntopNMovieId = avgRating.sort_values(ascending=False).index[:N]\ntopNMovieId"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["movie_data.info()"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["topNMovieId"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["# Wrapping it up in a function\ndef topN(user,N=3):\n    KnearestUsers = nearestNeighbours(user)\n    NNRatings = userMovieRatingMatrix[userMovieRatingMatrix.index.isin(KnearestUsers)]\n    avgRating = NNRatings.apply(np.nanmean).dropna()\n    moviesAlreadySeen = userMovieRatingMatrix.transpose()[user].dropna().index\n    avgRating = avgRating[~avgRating.index.isin(moviesAlreadySeen)]\n    topNMovieId = avgRating.sort_values(ascending=False).index[:N]\n    return pd.DataFrame({'Movie':pd.Series(topNMovieId).apply(movieTitle), 'Genre':pd.Series(topNMovieId).apply(movieGenre)})\n"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["# To remove the RunTimeWarning error \nimport warnings\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n\ngenre = topN(3,5)\n"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["genre"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["display(genre.groupby('Genre').count())"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":37}],"metadata":{"name":"Notebook1","notebookId":524007686795443},"nbformat":4,"nbformat_minor":0}
